{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (data_import_tools.py, line 17)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/karen/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3457\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_20768/3029949851.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from network_evaluation_tools import data_import_tools as dit\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/karen/Documents/GitHub/Network_Evaluation_Tools/Network Evaluation Examples/network_evaluation_tools/data_import_tools.py\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    print str(round(q*100,2))+'%', 'score:', q_score\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from network_evaluation_tools import data_import_tools as dit\n",
    "from network_evaluation_tools import network_evaluation_functions as nef\n",
    "from network_evaluation_tools import network_propagation as prop\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/karen/Documents/GitHub/Network_Evaluation_Tools\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_network_folder = 'Data/Networks/'\n",
    "evaluation_network_folder = 'Data/NetworkCYJS/'\n",
    "evaluation_lists_folder = 'Data/Evaluations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, path\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_networks = [evaluation_network_folder+f for f in listdir(evaluation_network_folder) if isfile(join(evaluation_network_folder, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluation_lists_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20768/2346576653.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist_evaluations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mevaluation_lists_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_lists_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_lists_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluation_lists_folder' is not defined"
     ]
    }
   ],
   "source": [
    "list_evaluations = [evaluation_lists_folder+f for f in listdir(evaluation_lists_folder) if isfile(join(evaluation_lists_folder, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network_name = path.splitext(evaluating_file)[0].split(evaluation_lists_folder)[1] +\"_\" + path.splitext(evaluating_network)[0].split(evaluation_network_folder)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_evaluations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20768/2903274948.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mperformances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgains\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mevaluating_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_evaluations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mgenesets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_node_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluating_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mevaluating_network\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_networks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'list_evaluations' is not defined"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "performances = {}\n",
    "gains = {}\n",
    "for evaluating_file in list_evaluations:\n",
    "    genesets = dit.load_node_sets(evaluating_file)\n",
    "    for evaluating_network in list_networks:\n",
    "        network_name = path.splitext(evaluating_file)[0].split(evaluation_lists_folder)[1] +\"_\" + path.splitext(evaluating_network)[0].split(evaluation_network_folder)[1]\n",
    "        network = nx.read_gpickle(evaluating_network)\n",
    "        genesets_p = nef.calculate_p(network, genesets)\n",
    "        network_nodes = [str(gene) for gene in network.nodes()]\n",
    "        nodesets_p = {}\n",
    "        selected = {}\n",
    "        m=-0.18887257\n",
    "        b=0.64897403\n",
    "        nodesets = genesets\n",
    "        for nodeset in nodesets:\n",
    "                nodesets_coverage = len([node for node in nodesets[nodeset] if node in network_nodes])\n",
    "                if nodesets_coverage > 0:\n",
    "                    nodesets_p[nodeset] = round(m*np.log10(nodesets_coverage)+b, 4)\n",
    "                    selected[nodeset] = nodesets[nodeset]\n",
    "                else:\n",
    "                    print (nodeset, ' does not have common genes')\n",
    "        genesets_p = nodesets_p\n",
    "        genesets = selected\n",
    "        alpha = prop.calculate_alpha(network)\n",
    "        kernel = nef.construct_prop_kernel(network, alpha=alpha, verbose=True)\n",
    "        AUPRC_values = nef.small_network_AUPRC_wrapper(kernel, genesets, genesets_p, n=30, cores=1, verbose=True)\n",
    "        null_AUPRCs = []\n",
    "        for i in range(10):\n",
    "            shuffNet = nef.shuffle_network(network, max_tries_n=10, verbose=True)\n",
    "            shuffNet_kernel = nef.construct_prop_kernel(shuffNet, alpha=alpha, verbose=False)\n",
    "            shuffNet_AUPRCs = nef.small_network_AUPRC_wrapper(shuffNet_kernel, genesets, genesets_p, n=30, cores=4, verbose=False)\n",
    "            null_AUPRCs.append(shuffNet_AUPRCs)\n",
    "            # # print 'shuffNet', repr(i+1), 'AUPRCs calculated'\n",
    "        null_AUPRCs_table = pd.concat(null_AUPRCs, axis=1)\n",
    "        null_AUPRCs_table.columns = ['shuffNet'+repr(i+1) for i in range(len(null_AUPRCs))]\n",
    "        network_performance = nef.calculate_network_performance_score(AUPRC_values, null_AUPRCs_table, verbose=True)\n",
    "        network_performance.name = network_name\n",
    "        network_perf_gain = nef.calculate_network_performance_gain(AUPRC_values, null_AUPRCs_table, verbose=True)\n",
    "        network_perf_gain.name = network_name\n",
    "        performances[network_name]=network_performance\n",
    "        gains[network_name]=network_performance\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances['elements']= section_lens\n",
    "gains['elements']= section_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.DataFrame(performances)\n",
    "df_p.to_csv('Data/Network_Performance_J.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g = pd.DataFrame(performances)\n",
    "df_g.to_csv('Data/Network_Performance_Gain_J.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(performances['DisGeNET_genesets_Young2Old_95_edge_14']).plot(kind='hist', bins=[0,10,20]) # `bins` defines the start and end points of bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rank network on average performance across gene sets vs performance on same gene sets in previous network set\n",
    "all_network_performance = pd.read_csv('Data/Network_Performance_J.csv', index_col=0, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_network_performance_filt = pd.concat([network_performance, all_network_performance.ix[network_performance.index]], axis=1)\n",
    "network_performance_rank_table = all_network_performance_filt.rank(axis=1, ascending=False)\n",
    "network_performance_rankings = network_performance_rank_table['Test Network']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank network on average performance gain across gene sets vs performance gain on same gene sets in previous network set\n",
    "all_network_perf_gain = pd.read_csv('Data/Network_Performance_Gain_J.csv', index_col=0, header=None)\n",
    "all_network_perf_gain_filt = pd.concat([network_perf_gain, all_network_perf_gain.ix[network_perf_gain.index]], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_network_perf_gain_filt[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_perf_gain_rank_table = all_network_performance_filt.rank(axis=1, ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_perf_gain_rankings = network_perf_gain_rank_table['Test Network']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_perf_gain_rank_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Network Performance\n",
    "network_performance_metric_ranks = pd.concat([network_performance, network_performance_rankings, network_perf_gain, network_perf_gain_rankings], axis=1)\n",
    "network_performance_metric_ranks.columns = ['Network Performance', 'Network Performance Rank', 'Network Performance Gain', 'Network Performance Gain Rank']\n",
    "network_performance_metric_ranks.sort_values(by=['Network Performance Rank', 'Network Performance', 'Network Performance Gain Rank', 'Network Performance Gain'],\n",
    "                                             ascending=[True, False, True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Construct network summary table\n",
    "network_summary = {}\n",
    "network_summary['Nodes'] = int(len(network.nodes()))\n",
    "network_summary['Edges'] = int(len(network.edges()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_summary['Avg Node Degree'] = np.mean(dict(network.degree()).values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_summary['Edge Density'] = 2*network_summary['Edges'] / float((network_summary['Nodes']*(network_summary['Nodes']-1)))\n",
    "network_summary['Avg Network Performance Rank'] = network_performance_rankings.mean()\n",
    "network_summary['Avg Network Performance Rank, Rank'] = int(network_performance_rank_table.mean().rank().ix['Test Network'])\n",
    "network_summary['Avg Network Performance Gain Rank'] = network_perf_gain_rankings.mean()\n",
    "network_summary['Avg Network Performance Gain Rank, Rank'] = int(network_perf_gain_rank_table.mean().rank().ix['Test Network'])\n",
    "for item in ['Nodes', 'Edges' ,'Avg Node Degree', 'Edge Density', 'Avg Network Performance Rank', 'Avg Network Performance Rank, Rank',\n",
    "             'Avg Network Performance Gain Rank', 'Avg Network Performance Gain Rank, Rank']:\n",
    "    # print item+':\\t'+repr(network_summary[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
